{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab2-DL: E1-emosjoner-bygging.ipynb** (ELMED219) | Prioritet: 3 (valgfri)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arvidl/ELMED219-2026/blob/main/Lab2-DL/notebooks/E1-emosjoner-bygging.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üòä E1: CNN-klassifikasjon av ansiktsutrykk - Del 1 (Bygging)\n",
    "\n",
    "Denne notebook demonstrerer hvordan **Konvolusjonelle Nevrale Nettverk (CNN)** kan brukes til √• klassifisere ansiktsutrykk og emosjoner, og sammenligner dette med medisinske anvendelser.\n",
    "\n",
    "## M√•l\n",
    "- Bygge og trene en CNN for √• klassifisere 6 universelle emosjoner\n",
    "- Forst√• hvordan CNN fungerer p√• ansiktsbilder\n",
    "- Sammenligne med medisinske anvendelser (depresjon, smerte, nevrologiske tilstander)\n",
    "- Demonstrere evalueringsmetoder: forvirringsmatrise, CAM/Grad-CAM\n",
    "- Diskutere etiske aspekter (bias, personvern)\n",
    "- Illustrere formalismen **y ~ f(X, Œ∏)** i praksis\n",
    "\n",
    "## Datasett\n",
    "Vi bruker **FER2013** (Facial Expression Recognition 2013) datasettet med <strike>7</strike> 6 emosjonsklasser:\n",
    "- **<strike>Anger** (Sinne)</strike> - **denne er tom i FER2013**\n",
    "- ü§¢ **Disgust** (Avsky) \n",
    "- üò® **Fear** (Frykt)\n",
    "- üòä **Happy** (Glede)\n",
    "- üò¢ **Sad** (Tristhet)\n",
    "- üò≤ **Surprise** (Overraskelse)\n",
    "- üòê **Neutral** (N√∏ytral)\n",
    "\n",
    "## Teoretisk Fundament\n",
    "\n",
    "### Formalismen y ~ f(X, Œ∏)\n",
    "\n",
    "I maskinl√¶ring kan vi uttrykke emosjonsklassifikasjonsproblemet som:\n",
    "\n",
    "**y = f(X, Œ∏) + Œµ**\n",
    "\n",
    "Hvor:\n",
    "- **y** = predikert emosjon (0-5)\n",
    "- **X** = input ansiktsbilde (pikselverdier)\n",
    "- **Œ∏** = modellparametere (CNN-vekter)\n",
    "- **f** = ikke-line√¶r funksjon (CNN-arkitekturen)\n",
    "- **Œµ** = feilterm (noise)\n",
    "\n",
    "Dette er identisk med medisinsk bildeanalyse, bare med forskjellige klasser!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sammenligning: Emosjoner vs Medisinske Bilder\n",
    "\n",
    "| Aspekt | Emosjonsgjenkjenning | Medisinsk Bildeanalyse |\n",
    "|--------|---------------------|------------------------|\n",
    "| **Input (X)** | RGB/gr√•toner av ansikter | Multiparametrisk MRI, r√∏ntgen, CT |\n",
    "| **Klasser (y)** | 6 universelle emosjoner | Sykdomstilstander, anatomiske strukturer |\n",
    "| **Kompleksitet** | Mikro-uttrykk, kulturelle forskjeller | Anatomiske strukturer, patologier |\n",
    "| **Konsekvenser** | Psykologisk vurdering | Frisk - Syk |\n",
    "| **Datamengde** | Tusener av bilder | Begrenset (privacy, ekspertise) |\n",
    "| **Ekspertise** | Psykologi, nevrologi | Medisin, radiologi |\n",
    "| **Bias** | Kulturell, etnisk, kj√∏nnsbias | Demografisk, teknisk bias |\n",
    "\n",
    "**Felles prinsipper:**\n",
    "- Begge krever domenekunnskap\n",
    "- Begge har problemer med ubalanserte klasser  \n",
    "- Begge trenger robuste modeller\n",
    "- Begge har etiske implikasjoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Men f√∏rst: üîß milj√∏oppsett - kode skal fungere b√•de lokalt, i Codespaces samt Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üíª Kj√∏rer i lokal milj√∏/Codespaces\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "# Sjekk om vi kj√∏rer i Google Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"üöÄ Kj√∏rer i Google Colab\")\n",
    "else:\n",
    "    print(\"üíª Kj√∏rer i lokal milj√∏/Codespaces\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    # G√• til root-mappen\n",
    "    os.chdir('/content')\n",
    "    \n",
    "    # Sjekk n√•v√¶rende mappe\n",
    "    print(f\"N√•v√¶rende mappe: {os.getcwd()}\")\n",
    "    \n",
    "    # Sjekk om mappen allerede eksisterer\n",
    "    if os.path.exists('ELMED219-2026/Lab2-DL'):\n",
    "        print(\"‚úÖ ELMED219-2026/Lab2-DL mappen eksisterer allerede!\")\n",
    "        \n",
    "        # Sjekk innholdet\n",
    "        print(\"\\nüìÅ Innhold i ELMED219-2026/Lab2-DL mappen:\")\n",
    "        try:\n",
    "            result = subprocess.run(['ls', '-la', 'ELMED219-2026/Lab2-DL'], \n",
    "                                  capture_output=True, text=True, check=True)\n",
    "            print(result.stdout)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Kunne ikke liste innhold: {e}\")\n",
    "        \n",
    "        # Sjekk om det er en git repository\n",
    "        if os.path.exists('ELMED219-2026/Lab2-DL/.git'):\n",
    "            print(\"\\n‚úÖ Dette er en git repository!\")\n",
    "            \n",
    "            # G√• inn i mappen og oppdater\n",
    "            os.chdir('ELMED219-2026/Lab2-DL')\n",
    "            print(f\"üìÅ Byttet til: {os.getcwd()}\")\n",
    "            \n",
    "            # Pr√∏v √• oppdatere repositoryet\n",
    "            try:\n",
    "                result = subprocess.run(['git', 'pull'], \n",
    "                                      capture_output=True, text=True, check=True)\n",
    "                print(\"‚úÖ Repository oppdatert!\")\n",
    "                print(result.stdout)\n",
    "            except subprocess.CalledProcessError as e:\n",
    "                print(f\"‚ö†Ô∏è Kunne ikke oppdatere repository: {e}\")\n",
    "                print(\"Men mappen eksisterer og kan brukes!\")\n",
    "        else:\n",
    "            print(\"‚ö†Ô∏è Dette ser ikke ut som en git repository\")\n",
    "            \n",
    "    else:\n",
    "        print(\"ÔøΩÔøΩ Mappen eksisterer ikke - pr√∏ver git clone...\")\n",
    "        try:\n",
    "            result = subprocess.run(['git', 'clone', 'https://github.com/arvidl/ELMED219-2026.git'], \n",
    "                                  capture_output=True, text=True, check=True)\n",
    "            print(\"‚úÖ Repository klonet vellykket!\")\n",
    "            print(result.stdout)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            print(f\"‚ùå Git clone feilet: {e}\")\n",
    "            print(f\"Error output: {e.stderr}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if IN_COLAB:\n",
    "    !pip install opencv-python --quiet\n",
    "    !pip install tqdm --quiet\n",
    "    !pip install torchsummary --quiet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ GPU tilgjengelig: NVIDIA RTX A5000 Laptop GPU\n",
      "Bruker enhet: cuda\n"
     ]
    }
   ],
   "source": [
    "# Imports og setup med feilh√•ndtering\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import requests\n",
    "import zipfile\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import warnings\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Sjekk om GPU eller MPS er tilgjengelig og sett enhet (device)\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "    print(f'üöÄ GPU tilgjengelig: {torch.cuda.get_device_name(0)}')\n",
    "elif torch.backends.mps.is_available():\n",
    "    device = torch.device('mps')\n",
    "    print(' Apple Silicon MPS tilgjengelig')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "    print('üíª Bruker CPU')\n",
    "\n",
    "print(f'Bruker enhet: {device}')\n",
    "\n",
    "# Sett random seeds for reproduserbarhet\n",
    "torch.manual_seed(42)\n",
    "np.random.seed(42)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(42)\n",
    "    torch.cuda.manual_seed_all(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Data Lasting og Forberedelse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FER2013 Datasett\n",
    "\n",
    "**FER2013** (Facial Expression Recognition 2013) er et av de mest brukte datasettene for emosjonsgjenkjenning:\n",
    "\n",
    "- **St√∏rrelse**: 35,887 bilder\n",
    "- **Oppl√∏sning**: 48x48 piksler\n",
    "- **Format**: Gr√•toner\n",
    "- **Klasser**: 6 emosjoner (0-5)  [Oprinnelig 7 universelle emosjoner: \"Anger\" (sinne) mangler i FER2013]\n",
    "- **Split**: Training (28,709), PublicTest (3,589), PrivateTest (3,589)\n",
    "\n",
    "### Datasettstruktur\n",
    "```\n",
    "../data/\n",
    "‚îî‚îÄ‚îÄ ansiktsuttrykk/\n",
    "    ‚îú‚îÄ‚îÄ FER2013/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ train/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 0_disgust/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_fear/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_happy/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3_sad/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 4_surprise/\n",
    "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 5_neutral/\n",
    "    ‚îÇ   ‚îú‚îÄ‚îÄ val/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 0_disgust/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_fear/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_happy/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3_sad/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 4_surprise/\n",
    "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 5_neutral/\n",
    "    ‚îÇ   ‚îî‚îÄ‚îÄ test/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 0_disgust/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 1_fear/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 2_happy/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 3_sad/\n",
    "    ‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ 4_surprise/\n",
    "    ‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ 5_neutral/\n",
    "    ‚îî‚îÄ‚îÄ fer2013.csv\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hent_fer2013_dataset():\n",
    "    \"\"\"\n",
    "    Hent FER2013 datasettet fra Kaggle (hvis ikke allerede lastet ned)\n",
    "    \"\"\"\n",
    "    print(\"üì• Henter FER2013 datasett\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    data_dir = Path(\"../data/ansiktsuttrykk/FER2013\")\n",
    "    data_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Sjekk om data allerede eksisterer\n",
    "    existing_images = list(data_dir.glob(\"**/*.png\")) + list(data_dir.glob(\"**/*.jpg\"))\n",
    "    \n",
    "    if existing_images:\n",
    "        print(f\"‚úÖ Data allerede eksisterer: {len(existing_images)} bilder\")\n",
    "        return True\n",
    "    \n",
    "    # Pr√∏v √• laste ned fra Kaggle\n",
    "    try:\n",
    "        if IN_COLAB:\n",
    "            # I Colab, last ned fra Kaggle\n",
    "            !pip install kaggle --quiet\n",
    "            # Used to securely store your API key\n",
    "            from google.colab import userdata\n",
    "\n",
    "            # Load Kaggle credentials from Colab Secrets\n",
    "            try:\n",
    "                os.environ['KAGGLE_USERNAME'] = userdata.get('KAGGLE_USERNAME')\n",
    "                os.environ['KAGGLE_KEY'] = userdata.get('KAGGLE_KEY')\n",
    "                print(\"‚úÖ Kaggle credentials loaded from Colab Secrets!\")\n",
    "            except userdata.notebook_secret.NotebookAccessError:\n",
    "                print(\"‚ùå Could not load Kaggle credentials from Colab Secrets.\")\n",
    "                print(\"Please ensure you have added KAGGLE_USERNAME and KAGGLE_KEY to the Secrets manager (üîë icon) and enabled 'Notebook access'.\")\n",
    "                os.environ['KAGGLE_USERNAME'] = '' # Clear environment variables if access failed\n",
    "                os.environ['KAGGLE_KEY'] = ''\n",
    "\n",
    "            # Re-run the data download cell\n",
    "            !kaggle datasets download -d msambare/fer2013 -p {data_dir} --unzip\n",
    "        else:\n",
    "            # Lokalt, sjekk om Kaggle API er tilgjengelig\n",
    "            kaggle_path = Path.home() / \".kaggle\" / \"kaggle.json\"\n",
    "            if kaggle_path.exists():\n",
    "                print(\"‚úÖ Kaggle API credentials funnet!\")\n",
    "                print(\"üîÑ Pr√∏ver automatisk nedlasting...\")\n",
    "                \n",
    "                # Last ned datasettet\n",
    "                import subprocess\n",
    "                result = subprocess.run([\n",
    "                    \"kaggle\", \"datasets\", \"download\", \n",
    "                    \"-d\", \"msambare/fer2013\", \n",
    "                    \"-p\", str(data_dir), \"--unzip\"\n",
    "                ], capture_output=True, text=True)\n",
    "                \n",
    "                if result.returncode == 0:\n",
    "                    print(\"‚úÖ Datasett lastet ned!\")\n",
    "                else:\n",
    "                    print(f\"‚ùå Nedlasting feilet: {result.stderr}\")\n",
    "                    return False\n",
    "            else:\n",
    "                print(\"‚ö†Ô∏è Kaggle API credentials ikke funnet!\")\n",
    "                print(\"G√• til: https://www.kaggle.com/datasets/msambare/fer2013\")\n",
    "                print(f\"Last ned og ekstraher til: {data_dir}\")\n",
    "                return False\n",
    "        \n",
    "        # Sjekk om nedlasting var vellykket\n",
    "        downloaded_images = list(data_dir.glob(\"**/*.png\")) + list(data_dir.glob(\"**/*.jpg\"))\n",
    "        if downloaded_images:\n",
    "            print(f\"‚úÖ Nedlasting vellykket: {len(downloaded_images)} bilder\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"‚ùå Ingen bilder funnet etter nedlasting!\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Feil under nedlasting: {e}\")\n",
    "        return False\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üì• Henter FER2013 datasett\n",
      "==================================================\n",
      "‚úÖ Kaggle API credentials funnet!\n",
      "üîÑ Pr√∏ver automatisk nedlasting...\n",
      "‚úÖ Datasett lastet ned!\n",
      "‚úÖ Nedlasting vellykket: 35887 bilder\n",
      "CPU times: user 216 ms, sys: 26.1 ms, total: 242 ms\n",
      "Wall time: 5.53 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Hent data (hvis ikke allerede lastet ned)\n",
    "success = hent_fer2013_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def organiser_fer2013_dataset():\n",
    "    \"\"\"\n",
    "    Organiser FER2013 datasettet i train/val/test mapper\n",
    "    \"\"\"\n",
    "    print(\"üîß Organiserer FER2013 datasett\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    data_dir = Path(\"../data/ansiktsuttrykk/FER2013\")\n",
    "    \n",
    "    # Emosjonsklasser\n",
    "    emotion_classes = {\n",
    "        0: 'disgust', \n",
    "        1: 'fear',\n",
    "        2: 'happy',\n",
    "        3: 'sad',\n",
    "        4: 'surprise',\n",
    "        5: 'neutral'\n",
    "    }\n",
    "    \n",
    "    # Opprett undermapper for alle splits og emosjonsklasser\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        for emotion in emotion_classes.values():\n",
    "            (data_dir / split / emotion).mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    # Sjekk om data allerede er organisert\n",
    "    val_images = list((data_dir / \"val\").glob(\"**/*.png\")) + list((data_dir / \"val\").glob(\"**/*.jpg\"))\n",
    "    \n",
    "    if val_images:\n",
    "        print(\"‚úÖ Data allerede organisert!\")\n",
    "        return True\n",
    "    \n",
    "    # Hvis val-mappen er tom, flytt bilder fra train\n",
    "    print(\"üîÑ Val-mappen er tom - flytter bilder fra train...\")\n",
    "    \n",
    "    total_moved = 0\n",
    "    \n",
    "    # G√• gjennom hver emosjonsklasse\n",
    "    for emotion in emotion_classes.values():\n",
    "        train_emotion_dir = data_dir / \"train\" / emotion\n",
    "        val_emotion_dir = data_dir / \"val\" / emotion\n",
    "        \n",
    "        # Finn alle bilder i denne emosjonsklassen\n",
    "        emotion_images = list(train_emotion_dir.glob(\"*.png\")) + list(train_emotion_dir.glob(\"*.jpg\"))\n",
    "        \n",
    "        if not emotion_images:\n",
    "            print(f\"  ‚ö†Ô∏è {emotion}: Ingen bilder funnet i train\")\n",
    "            continue\n",
    "            \n",
    "        # Flytt 15% av bildene til val\n",
    "        val_count = int(len(emotion_images) * 0.15)\n",
    "        \n",
    "        if val_count > 0:\n",
    "            print(f\"  {emotion}: {len(emotion_images)} bilder ‚Üí flytter {val_count} til val\")\n",
    "            \n",
    "            # Flytt bildene\n",
    "            moved_count = 0\n",
    "            for image_path in emotion_images:\n",
    "                if moved_count >= val_count:\n",
    "                    break\n",
    "                    \n",
    "                # Opprett ny sti i val-mappen\n",
    "                val_path = val_emotion_dir / image_path.name\n",
    "                \n",
    "                # Flytt bildet\n",
    "                try:\n",
    "                    image_path.rename(val_path)\n",
    "                    moved_count += 1\n",
    "                    total_moved += 1\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ö†Ô∏è Kunne ikke flytte {image_path.name}: {e}\")\n",
    "        else:\n",
    "            print(f\"  {emotion}: {len(emotion_images)} bilder ‚Üí ingen flyttet (for f√• bilder)\")\n",
    "    \n",
    "    print(f\"‚úÖ Flyttet totalt {total_moved} bilder til val!\")\n",
    "    \n",
    "    # Vis statistikk\n",
    "    print(\"\\nÔøΩÔøΩ Ny organisering:\")\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_images = list((data_dir / split).glob(\"**/*.png\")) + list((data_dir / split).glob(\"**/*.jpg\"))\n",
    "        print(f\"  {split}: {len(split_images)} bilder\")\n",
    "        \n",
    "        # Vis per emosjonsklasse\n",
    "        for emotion in emotion_classes.values():\n",
    "            emotion_images = list((data_dir / split / emotion).glob(\"*.png\")) + list((data_dir / split / emotion).glob(\"*.jpg\"))\n",
    "            if emotion_images:\n",
    "                print(f\"    {emotion}: {len(emotion_images)} bilder\")\n",
    "    \n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß Organiserer FER2013 datasett\n",
      "==================================================\n",
      "üîÑ Val-mappen er tom - flytter bilder fra train...\n",
      "  disgust: 436 bilder ‚Üí flytter 65 til val\n",
      "  fear: 4097 bilder ‚Üí flytter 614 til val\n",
      "  happy: 7215 bilder ‚Üí flytter 1082 til val\n",
      "  sad: 4830 bilder ‚Üí flytter 724 til val\n",
      "  surprise: 3171 bilder ‚Üí flytter 475 til val\n",
      "  neutral: 4965 bilder ‚Üí flytter 744 til val\n",
      "‚úÖ Flyttet totalt 3704 bilder til val!\n",
      "\n",
      "ÔøΩÔøΩ Ny organisering:\n",
      "  train: 25005 bilder\n",
      "    disgust: 371 bilder\n",
      "    fear: 3483 bilder\n",
      "    happy: 6133 bilder\n",
      "    sad: 4106 bilder\n",
      "    surprise: 2696 bilder\n",
      "    neutral: 4221 bilder\n",
      "  val: 3704 bilder\n",
      "    disgust: 65 bilder\n",
      "    fear: 614 bilder\n",
      "    happy: 1082 bilder\n",
      "    sad: 724 bilder\n",
      "    surprise: 475 bilder\n",
      "    neutral: 744 bilder\n",
      "  test: 7178 bilder\n",
      "    disgust: 111 bilder\n",
      "    fear: 1024 bilder\n",
      "    happy: 1774 bilder\n",
      "    sad: 1247 bilder\n",
      "    surprise: 831 bilder\n",
      "    neutral: 1233 bilder\n"
     ]
    }
   ],
   "source": [
    "# Organiser data (hvis ikke allerede organisert)\n",
    "if success:\n",
    "    organiser_fer2013_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ FER2013 data eksisterer: 35887 bilder\n",
      "\n",
      "TRAIN:\n",
      "  disgust: 371 bilder\n",
      "  fear: 3483 bilder\n",
      "  happy: 6133 bilder\n",
      "  sad: 4106 bilder\n",
      "  surprise: 2696 bilder\n",
      "  neutral: 4221 bilder\n",
      "\n",
      "VAL:\n",
      "  disgust: 65 bilder\n",
      "  fear: 614 bilder\n",
      "  happy: 1082 bilder\n",
      "  sad: 724 bilder\n",
      "  surprise: 475 bilder\n",
      "  neutral: 744 bilder\n",
      "\n",
      "TEST:\n",
      "  disgust: 111 bilder\n",
      "  fear: 1024 bilder\n",
      "  happy: 1774 bilder\n",
      "  sad: 1247 bilder\n",
      "  surprise: 831 bilder\n",
      "  neutral: 1233 bilder\n"
     ]
    }
   ],
   "source": [
    "def check_fer2013_data():\n",
    "    \"\"\"Sjekk om FER2013 data eksisterer og er organisert\"\"\"\n",
    "    data_dir = Path(\"../data/ansiktsuttrykk/FER2013\")\n",
    "    \n",
    "    # Sjekk om bilder eksisterer\n",
    "    existing_images = list(data_dir.glob(\"**/*.jpg\")) + list(data_dir.glob(\"**/*.png\"))\n",
    "    \n",
    "    if existing_images:\n",
    "        print(f\"‚úÖ FER2013 data eksisterer: {len(existing_images)} bilder\")\n",
    "        \n",
    "        # Tell bilder per split og emosjon\n",
    "        splits = ['train', 'val', 'test']\n",
    "        emotions = ['anger', 'disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
    "        \n",
    "        for split in splits:\n",
    "            print(f\"\\n{split.upper()}:\")\n",
    "            for emotion in emotions:\n",
    "                count = len(list((data_dir / split / emotion).glob(\"*.jpg\")) + \n",
    "                           list((data_dir / split / emotion).glob(\"*.png\")))\n",
    "                if count > 0:\n",
    "                    print(f\"  {emotion}: {count} bilder\")\n",
    "        \n",
    "        return True\n",
    "    else:\n",
    "        print(\"‚ùå Ingen FER2013 data funnet\")\n",
    "        return False\n",
    "\n",
    "# Kj√∏r sjekk\n",
    "data_ready = check_fer2013_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionDataset(Dataset):\n",
    "    \"\"\"Custom dataset for emotion classification\"\"\"\n",
    "    \n",
    "    def __init__(self, image_paths, labels, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        image = Image.open(image_path).convert('L')  # Gr√•toner\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_emotion_data(data_dir, test_size=0.2, val_size=0.2):\n",
    "    \"\"\"Last og splitt emosjonsdatasett\"\"\"\n",
    "    \n",
    "    # Emosjonsklasser\n",
    "    emotion_classes = {\n",
    "        0: 'disgust', \n",
    "        1: 'fear',\n",
    "        2: 'happy',\n",
    "        3: 'sad',\n",
    "        4: 'surprise',\n",
    "        5: 'neutral'\n",
    "    }\n",
    "    \n",
    "    # Samle alle bilde-sti og etiketter\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    \n",
    "    for split in ['train', 'val', 'test']:\n",
    "        split_dir = os.path.join(data_dir, split)\n",
    "        if os.path.exists(split_dir):\n",
    "            for emotion_name in emotion_classes.values():\n",
    "                emotion_dir = os.path.join(split_dir, emotion_name)\n",
    "                if os.path.exists(emotion_dir):\n",
    "                    for filename in os.listdir(emotion_dir):\n",
    "                        if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "                            image_paths.append(os.path.join(emotion_dir, filename))\n",
    "                            # Finn emosjonsindeks\n",
    "                            emotion_idx = [k for k, v in emotion_classes.items() if v == emotion_name][0]\n",
    "                            labels.append(emotion_idx)\n",
    "    \n",
    "    print(f\"Totalt bilder funnet: {len(image_paths)}\")\n",
    "    print(f\"Emosjoner: {list(emotion_classes.values())}\")\n",
    "    print(f\"Bilder per emosjon: {np.bincount(labels)}\")\n",
    "    \n",
    "    # Splitt data hvis n√∏dvendig\n",
    "    if len(set(labels)) > 1:  # Sjekk om vi har flere klasser\n",
    "        X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "            image_paths, labels, test_size=test_size + val_size, \n",
    "            random_state=42, stratify=labels\n",
    "        )\n",
    "        \n",
    "        X_val, X_test, y_val, y_test = train_test_split(\n",
    "            X_temp, y_temp, test_size=test_size/(test_size + val_size),\n",
    "            random_state=42, stratify=y_temp\n",
    "        )\n",
    "    else:\n",
    "        # Fallback hvis vi bare har √©n klasse\n",
    "        X_train, X_val, X_test = image_paths, image_paths, image_paths\n",
    "        y_train, y_val, y_test = labels, labels, labels\n",
    "    \n",
    "    return (X_train, y_train), (X_val, y_val), (X_test, y_test), list(emotion_classes.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Data transformasjoner definert!\n"
     ]
    }
   ],
   "source": [
    "# Data transformasjoner\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.RandomAffine(degrees=0, translate=(0.1, 0.1)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normaliser gr√•toner\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize((48, 48)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])\n",
    "])\n",
    "\n",
    "print(\"‚úÖ Data transformasjoner definert!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. CNN Modell for Emosjonsgjenkjenning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EmotionNet(nn.Module):\n",
    "    \"\"\"CNN for emosjonsklassifikasjon\"\"\"\n",
    "    \n",
    "    emotion_classes = {\n",
    "        0: 'disgust', \n",
    "        1: 'fear',\n",
    "        2: 'happy',\n",
    "        3: 'sad',\n",
    "        4: 'surprise',\n",
    "        5: 'neutral'\n",
    "    }\n",
    "    \n",
    "    def __init__(self, num_classes=len(emotion_classes), dropout_rate=0.5):\n",
    "        super(EmotionNet, self).__init__()\n",
    "        \n",
    "        # Feature extraction layers\n",
    "        self.features = nn.Sequential(\n",
    "            # Block 1\n",
    "            nn.Conv2d(1, 32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Block 2  \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Block 3\n",
    "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "            \n",
    "            # Block 4\n",
    "            nn.Conv2d(128, 256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout2d(0.25),\n",
    "        )\n",
    "        \n",
    "        # Adaptive pooling for ulike input-st√∏rrelser\n",
    "        self.adaptive_pool = nn.AdaptiveAvgPool2d((3, 3))\n",
    "        \n",
    "        # Klassifikator\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256 * 3 * 3, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = self.adaptive_pool(x)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forklaring av EmotionNet arkitekturen\n",
    "\n",
    "**EmotionNet** er spesielt designet for emosjonsgjenkjenning med f√∏lgende egenskaper:\n",
    "\n",
    "#### **1. Input Layer**\n",
    "- **1 kanal**: Gr√•toner (FER2013 er gr√•toner)\n",
    "- **48x48 piksler**: Standard FER2013 oppl√∏sning\n",
    "\n",
    "#### **2. Feature Extraction (4 blokker)**\n",
    "```python\n",
    "# Block 1: Grunnleggende kanter og teksturer\n",
    "Conv2d(1, 32, 3x3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool(2x2) ‚Üí Dropout2d(0.25)\n",
    "\n",
    "# Block 2: Mer komplekse m√∏nstre\n",
    "Conv2d(32, 64, 3x3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool(2x2) ‚Üí Dropout2d(0.25)\n",
    "\n",
    "# Block 3: H√∏yere niv√• features\n",
    "Conv2d(64, 128, 3x3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool(2x2) ‚Üí Dropout2d(0.25)\n",
    "\n",
    "# Block 4: Komplekse emosjonelle features\n",
    "Conv2d(128, 256, 3x3) ‚Üí BatchNorm ‚Üí ReLU ‚Üí MaxPool(2x2) ‚Üí Dropout2d(0.25)\n",
    "```\n",
    "\n",
    "#### **3. Regularisering**\n",
    "- **BatchNorm2d**: Stabiliserer trening\n",
    "- **Dropout2d**: Forhindrer overfitting\n",
    "- **Dropout**: I fully-connected layers\n",
    "\n",
    "#### **4. Klassifikator**\n",
    "- **AdaptiveAvgPool2d(3x3)**: Reduserer til 3x3 spatial dimensjoner\n",
    "- **3 FC layers**: 256√ó9 ‚Üí 512 ‚Üí 256 ‚Üí 6\n",
    "- **6 output klasser**: 6 emosjoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treningsfunksjoner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, device):\n",
    "    \"\"\"Tren model for √©n epoke\"\"\"\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in tqdm(dataloader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc\n",
    "\n",
    "def validate_epoch(model, dataloader, criterion, device):\n",
    "    \"\"\"Valider model for √©n epoke\"\"\"\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(dataloader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    \n",
    "    epoch_loss = running_loss / len(dataloader)\n",
    "    epoch_acc = 100 * correct / total\n",
    "    \n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, train_loader, val_loader, num_epochs=50, learning_rate=0.001):\n",
    "    \"\"\"Tren den fullstendige modellen\"\"\"\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, 'min', patience=5, factor=0.5)\n",
    "    \n",
    "    train_losses, val_losses = [], []\n",
    "    train_accs, val_accs = [], []\n",
    "    best_val_acc = 0.0\n",
    "    patience_counter = 0\n",
    "    \n",
    "    print(\"Starter trening...\")\n",
    "    print(\"=\" * 50)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"\\nEpoke {epoch+1}/{num_epochs}\")\n",
    "        print(\"-\" * 30)\n",
    "        \n",
    "        # Train\n",
    "        train_loss, train_acc = train_epoch(model, train_loader, criterion, optimizer, device)\n",
    "        \n",
    "        # Validate\n",
    "        val_loss, val_acc = validate_epoch(model, val_loader, criterion, device)\n",
    "        \n",
    "        # Update learning rate\n",
    "        scheduler.step(val_loss)\n",
    "        \n",
    "        # Store metrics\n",
    "        train_losses.append(train_loss)\n",
    "        val_losses.append(val_loss)\n",
    "        train_accs.append(train_acc)\n",
    "        val_accs.append(val_acc)\n",
    "        \n",
    "        print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.2f}%\")\n",
    "        print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.2f}%\")\n",
    "        print(f\"Learning Rate: {optimizer.param_groups[0]['lr']:.6f}\")\n",
    "        \n",
    "        # Early stopping\n",
    "        if val_acc > best_val_acc:\n",
    "            best_val_acc = val_acc\n",
    "            patience_counter = 0\n",
    "            # Save best model\n",
    "            torch.save(model.state_dict(), './modeller/best_emotion_model.pth')\n",
    "        else:\n",
    "            patience_counter += 1\n",
    "            \n",
    "        if patience_counter >= 10:\n",
    "            print(f\"\\nEarly stopping at epoch {epoch+1}\")\n",
    "            break\n",
    "    \n",
    "    return {\n",
    "        'train_losses': train_losses,\n",
    "        'val_losses': val_losses, \n",
    "        'train_accs': train_accs,\n",
    "        'val_accs': val_accs,\n",
    "        'best_val_acc': best_val_acc\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Hovedkj√∏ring - Del 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hovedkj√∏ring med automatisk oppsett\n",
    "def main_part1():\n",
    "    \"\"\"Hovedkj√∏ring del 1: Data lasting og modell oppsett\"\"\"\n",
    "    \n",
    "    print(\" Ansiktsutrykk-klassifikasjon med CNN - Del 1\")\n",
    "    print(\"=\" * 60)\n",
    "    \n",
    "    # Sett opp data-mapper\n",
    "    data_dir = \"../data/ansiktsuttrykk/FER2013\"\n",
    "    \n",
    "    # Sjekk om data eksisterer\n",
    "    if not os.path.exists(data_dir) or len(os.listdir(data_dir)) == 0:\n",
    "        print(\"‚ùå Data directory not found or empty!\")\n",
    "        print(\"\\nüîÑ Pr√∏ver automatisk oppsett...\")\n",
    "        \n",
    "        # Pr√∏v automatisk nedlasting\n",
    "        success = download_fer2013_dataset()\n",
    "        \n",
    "        if not success:\n",
    "            print(\"\\n‚ùå Automatisk oppsett feilet!\")\n",
    "            print(\"\\nüìã Manuell nedlasting:\")\n",
    "            print(\"1. G√• til: https://www.kaggle.com/datasets/msambare/fer2013\")\n",
    "            print(\"2. Last ned 'fer2013.zip'\")\n",
    "            print(\"3. Ekstraher til '../data/ansiktsuttrykk/' mappen\")\n",
    "            return None, None, None, None, None\n",
    "    else:\n",
    "        print(\"‚úÖ Data-katalog funnet!\")\n",
    "    \n",
    "    # Last data\n",
    "    print(\"\\n Laster data...\")\n",
    "    (X_train, y_train), (X_val, y_val), (X_test, y_test), class_names = load_emotion_data(data_dir)\n",
    "    \n",
    "    # Etabler datasett\n",
    "    print(\"\\nüîß Etablerer trening-, validering- og test-datasett...\")\n",
    "    train_dataset = EmotionDataset(X_train, y_train, train_transform)\n",
    "    val_dataset = EmotionDataset(X_val, y_val, val_transform)\n",
    "    test_dataset = EmotionDataset(X_test, y_test, val_transform)\n",
    "    \n",
    "    # Etabler data-laster \n",
    "    train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, num_workers=0)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"‚úÖ Lasting av data vellykket!\")\n",
    "    print(f\"Trening: {len(train_dataset)} bilder\")\n",
    "    print(f\"Validering: {len(val_dataset)} bilder\") \n",
    "    print(f\"Test: {len(test_dataset)} bilder\")\n",
    "    \n",
    "    # Bygg modell\n",
    "    print(\"\\nÔøΩÔøΩÔ∏è Bygger modell...\")\n",
    "    model = EmotionNet(num_classes=len(class_names)).to(device)\n",
    "    print(f\"Model parameters: {sum(p.numel() for p in model.parameters()):,}\")\n",
    "    \n",
    "    return model, train_loader, val_loader, test_loader, class_names\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ansiktsutrykk-klassifikasjon med CNN - Del 1\n",
      "============================================================\n",
      "‚úÖ Data-katalog funnet!\n",
      "\n",
      " Laster data...\n",
      "Totalt bilder funnet: 30934\n",
      "Emosjoner: ['disgust', 'fear', 'happy', 'sad', 'surprise', 'neutral']\n",
      "Bilder per emosjon: [ 547 5121 8989 6077 4002 6198]\n",
      "\n",
      "üîß Etablerer trening-, validering- og test-datasett...\n",
      "‚úÖ Lasting av data vellykket!\n",
      "Trening: 18560 bilder\n",
      "Validering: 6187 bilder\n",
      "Test: 6187 bilder\n",
      "\n",
      "ÔøΩÔøΩÔ∏è Bygger modell...\n",
      "Model parameters: 1,701,830\n"
     ]
    }
   ],
   "source": [
    "# Kj√∏r hovedkj√∏ring\n",
    "model, train_loader, val_loader, test_loader, class_names = main_part1()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Modell Sammendrag:\n",
      "==================================================\n",
      "üß™ Tester modell med dummy input...\n",
      "‚úÖ Modell test vellykket!\n",
      "Input shape: torch.Size([1, 1, 48, 48])\n",
      "Output shape: torch.Size([1, 6])\n",
      "Output device: cuda:0\n",
      "\n",
      "üìã Modell Detaljer:\n",
      "Modell: EmotionNet(\n",
      "  (features): Sequential(\n",
      "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (4): Dropout2d(p=0.25, inplace=False)\n",
      "    (5): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (6): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (7): ReLU(inplace=True)\n",
      "    (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (9): Dropout2d(p=0.25, inplace=False)\n",
      "    (10): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): Dropout2d(p=0.25, inplace=False)\n",
      "    (15): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (16): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (19): Dropout2d(p=0.25, inplace=False)\n",
      "  )\n",
      "  (adaptive_pool): AdaptiveAvgPool2d(output_size=(3, 3))\n",
      "  (classifier): Sequential(\n",
      "    (0): Flatten(start_dim=1, end_dim=-1)\n",
      "    (1): Linear(in_features=2304, out_features=512, bias=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): Dropout(p=0.5, inplace=False)\n",
      "    (4): Linear(in_features=512, out_features=256, bias=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): Dropout(p=0.5, inplace=False)\n",
      "    (7): Linear(in_features=256, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "Enhet: cuda\n",
      "Input st√∏rrelse: (batch_size, 1, 48, 48)\n",
      "Output st√∏rrelse: (batch_size, 6)\n",
      "\n",
      "‚ö†Ô∏è torchsummary feilet: Input type (torch.cuda.FloatTensor) and weight type (torch.FloatTensor) should be the same\n",
      "Bruker manuell modellvisning i stedet\n"
     ]
    }
   ],
   "source": [
    "# Vis modellstruktur\n",
    "print(\"\\nüìä Modell Sammendrag:\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "# Test modellen med dummy input f√∏rst\n",
    "print(\"üß™ Tester modell med dummy input...\")\n",
    "try:\n",
    "    dummy_input = torch.randn(1, 1, 48, 48).to(device)\n",
    "    with torch.no_grad():\n",
    "        output = model(dummy_input)\n",
    "    print(f\"‚úÖ Modell test vellykket!\")\n",
    "    print(f\"Input shape: {dummy_input.shape}\")\n",
    "    print(f\"Output shape: {output.shape}\")\n",
    "    print(f\"Output device: {output.device}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Modell test feilet: {e}\")\n",
    "\n",
    "# Vis modellstruktur manuelt\n",
    "print(f\"\\nüìã Modell Detaljer:\")\n",
    "print(f\"Modell: {model}\")\n",
    "print(f\"Enhet: {device}\")\n",
    "print(f\"Input st√∏rrelse: (batch_size, 1, 48, 48)\")\n",
    "print(f\"Output st√∏rrelse: (batch_size, {len(class_names)})\")\n",
    "\n",
    "# Pr√∏v torchsummary hvis modellen fungerer\n",
    "try:\n",
    "    from torchsummary import summary\n",
    "    # S√∏rg for at modellen er p√• CPU for torchsummary\n",
    "    model_cpu = model.cpu()\n",
    "    summary(model_cpu, input_size=(1, 48, 48))  # (kanaler, h√∏yde, bredde)\n",
    "    # Flytt modellen tilbake til riktig enhet\n",
    "    model = model.to(device)\n",
    "except ImportError:\n",
    "    print(\"\\n‚ö†Ô∏è torchsummary ikke tilgjengelig - installer med: pip install torchsummary\")\n",
    "except Exception as e:\n",
    "    print(f\"\\n‚ö†Ô∏è torchsummary feilet: {e}\")\n",
    "    print(\"Bruker manuell modellvisning i stedet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Oppsummering av Del 1\n",
    "\n",
    "**Del 1** av notebooken har n√•:\n",
    "\n",
    "‚úÖ **Milj√∏oppsett** - Fungerer p√• Colab, Codespaces og lokalt<br>\n",
    "‚úÖ **Device detection** - Automatisk GPU/MPS/CPU valg<br>\n",
    "‚úÖ **Data lasting** - FER2013 datasett med 7 emosjonsklasser<br>\n",
    "‚úÖ **Modell definisjon** - EmotionNet CNN arkitektur<br>\n",
    "‚úÖ **Treningsfunksjoner** - Komplette trenings- og valideringsfunksjoner<br>\n",
    "‚úÖ **Hovedkj√∏ring** - Automatisk oppsett og modell initialisering<br>\n",
    "\n",
    "**Neste steg** (Del 2) vil inkludere:\n",
    "- Visuell inspeksjon av data\n",
    "- Modell trening\n",
    "- Evaluering og visualisering\n",
    "- CAM/Grad-CAM for forklarbar AI\n",
    "- Medisinske anvendelser og etiske diskusjoner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai-helse-cuda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
