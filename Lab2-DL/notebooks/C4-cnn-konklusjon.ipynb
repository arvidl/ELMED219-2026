{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Lab2-DL: C4-cnn-konklusjon.ipynb** (ELMED219) | Prioritet: 2 (anbefalt)\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arvidl/ELMED219-2026/blob/main/Lab2-DL/notebooks/C4-cnn-konklusjon.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üöÄ C4: CNN Konklusjon og Veien Videre\n",
    "\n",
    "**Fra Natur til Medisin: Oppsummering og Kunnskapsstoff om CNN i Helse**\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ M√•l for denne delen\n",
    "\n",
    "I denne notebooken skal vi:\n",
    "- **Oppsummere** det vi har l√¶rt om CNN\n",
    "- **Sammenligne** naturlige og medisinske bilder\n",
    "- **Utforske** kunnskapsstoff om CNN i helse\n",
    "- **Se** veien videre i AI og helse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìä Oppsummering av det vi har l√¶rt\n",
    "\n",
    "### üèóÔ∏è CNN-arkitektur\n",
    "\n",
    "Vi har bygget en CNN-modell med:\n",
    "- **3 konvolusjonslag** med ReLU-aktivering\n",
    "- **Max pooling** for dimensjonsreduksjon\n",
    "- **Dropout** for √• forhindre overfitting\n",
    "- **Fully connected layers** for klassifikasjon\n",
    "\n",
    "### ‚ÅâÔ∏è Treningsresultater\n",
    "\n",
    "V√•r modell oppn√•dde:\n",
    "- **H√∏y n√∏yaktighet** p√• treningsdata\n",
    "- **God generalisering** p√• valideringsdata\n",
    "- **Robust prediksjon** p√• testdata\n",
    "\n",
    "### ‚ÅâÔ∏è Forklarbar AI\n",
    "\n",
    "Med Grad-CAM kunne vi:\n",
    "- **Visualisere** hvilke deler av bildet modellen fokuserer p√•\n",
    "- **Forst√•** modellens beslutningsprosess\n",
    "- **Validere** at modellen ser p√• riktige trekk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü©∫ Sammenligning: Natur vs Medisin\n",
    "\n",
    "### Likheter\n",
    "\n",
    "| Aspekt | Blomsterklassifikasjon | Medisinsk Bildeanalyse |\n",
    "|--------|------------------------|------------------------|\n",
    "| **Input** | RGB-bilder | MRI, CT, r√∏ntgen |\n",
    "| **M√•l** | Klassifiser blomstertype | Diagnostiser sykdom |\n",
    "| **Trekk** | Farge, form, tekstur | Anatomiske strukturer |\n",
    "| **Utfordringer** | Variasjon i lys, vinkel | St√∏y, artefakter |\n",
    "| **Konsekvenser** | Estetisk verdi | Frisk vs syk |\n",
    "\n",
    "### Forskjeller\n",
    "\n",
    "| Aspekt | Blomster | Medisin |\n",
    "|--------|----------|----------|\n",
    "| **Datamengde** | Tusener av bilder | Begrenset (privacy) |\n",
    "| **Ekspertise** | Botanikk | Medisin/radiologi |\n",
    "| **Regulering** | Minimal | FDA, CE-markering |\n",
    "| **Etikk** | Estetisk | Liv og helse / sykdom og d√∏d |\n",
    "| **Feilrate** | Akseptabel | Kritisk |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè• CNN i Medisinsk Bildeanalyse\n",
    "\n",
    "### üß† Hjerne-avbildning\n",
    "\n",
    "**MRI-analyse:**\n",
    "- **Alzheimer's sykdom**: Tidlig deteksjon av hjerneatrofi\n",
    "- **Tumor**: Identifikasjon av maligne vs benigne lesjoner\n",
    "- **Stroke**: Akutt deteksjon av iskemiske omr√•der\n",
    "\n",
    "**CT-scan:**\n",
    "- **Hjerneslag**: Deteksjon av bl√∏dning\n",
    "- **Skallebrudd**: Automatisk identifikasjon\n",
    "- **Kreft**: Staging og behandlingsplanlegging\n",
    "\n",
    "### üëÅÔ∏è √òye-avbildning\n",
    "\n",
    "**Fundus-fotografi:**\n",
    "- **Diabetisk retinopati**: Tidlig deteksjon av skader\n",
    "- **Glaukom**: Optisk nerve-skader\n",
    "- **Makul√¶r degenerasjon**: Alders-relaterte endringer\n",
    "\n",
    "**OCT (Optical Coherence Tomography):**\n",
    "- **Retinal skader**: 3D-visualisering\n",
    "- **Kornea-avbildning**: Refraktiv kirurgi\n",
    "\n",
    "### ü´Ä Kardiovaskul√¶r avbildning\n",
    "\n",
    "**Echokardiografi:**\n",
    "- **Hjertefunksjon**: Ejeksjonsfraksjon\n",
    "- **Klaffesykdom**: Mitralprolaps\n",
    "- **Kongestiv hjertesvikt**: Tidlig deteksjon\n",
    "\n",
    "**Angiografi:**\n",
    "- **Koronar sykdom**: Arteriell stenose\n",
    "- **Aneurysmer**: Aortadilatasjon\n",
    "- **Perifer arteriell sykdom**: Blodstr√∏ms-okklusjon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üî¨ Avanserte CNN-arkitekturer i Medisin\n",
    "\n",
    "### üèóÔ∏è ResNet (Residual Networks)\n",
    "\n",
    "**Hvorfor viktig i medisin:**\n",
    "- **Dype nettverk**: Kan l√¶re komplekse m√∏nstre\n",
    "- **Gradient flow**: Unng√•r vanishing gradient problem\n",
    "- **Transfer learning**: Bruk pretrente modeller\n",
    "\n",
    "**Medisinske applikasjoner:**\n",
    "- **Radiologi**: Chest X-ray analyse\n",
    "- **Patologi**: Histologisk bildeanalyse\n",
    "- **Dermatologi**: Hudlesjon-klassifikasjon\n",
    "\n",
    "### üîÑ U-Net (Segmentering)\n",
    "\n",
    "**Hvorfor viktig i medisin:**\n",
    "- **Piksel-/voxel-vis klassifikasjon**: Segmenter anatomiske strukturer\n",
    "- **Skip connections**: Bevarer detaljer\n",
    "- **End-to-end trening**: Optimaliserer for segmentering\n",
    "\n",
    "**Medisinske applikasjoner:**\n",
    "- **Tumor-segmentering**: MRI, CT\n",
    "- **Organ-segmentering**: Hjerte, lever, nyrer\n",
    "- **Kar-segmentering**: Angiografi\n",
    "\n",
    "### üéØ Fokus og forklarbarhet mekanismer\n",
    "\n",
    "**Hvorfor viktig i medisin:**\n",
    "- **Fokus**: Modellen fokuserer p√• relevante omr√•der\n",
    "- **Forklarbarhet**: Kan vise hvor modellen \"ser\"\n",
    "- **Robusthet**: Mindre p√•virket av irrelevante detaljer\n",
    "\n",
    "**Medisinske applikasjoner:**\n",
    "- **Lesion detection**: Fokus p√• patologiske omr√•der\n",
    "- **Multi-modal fusion**: Kombinerer ulike bildetyper\n",
    "- **Temporal analyse**: Ser p√• endringer over tid"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìö Litteratur og Ressurser\n",
    "\n",
    "### üìñ Grunnleggende Litteratur\n",
    "\n",
    "**CNN og Deep Learning:**\n",
    "1. **LeCun, Y., et al. (2015)**. \"Deep learning\". Nature, 521(7553), 436-444.\n",
    "2. **Goodfellow, I., et al. (2016)**. \"Deep Learning\". MIT Press.\n",
    "3. **Krizhevsky, A., et al. (2012)**. \"ImageNet classification with deep convolutional neural networks\". NIPS.\n",
    "\n",
    "**Medisinsk AI:**\n",
    "1. **Topol, E. J. (2019)**. \"High-performance medicine: the convergence of human and artificial intelligence\". Nature Medicine, 25(1), 44-56.\n",
    "2. **Esteva, A., et al. (2017)**. \"Dermatologist-level classification of skin cancer with deep neural networks\". Nature, 542(7639), 115-118.\n",
    "3. **Gulshan, V., et al. (2016)**. \"Development and validation of a deep learning algorithm for detection of diabetic retinopathy in retinal fundus photographs\". JAMA, 316(22), 2402-2410.\n",
    "\n",
    "### üé• Videoressurser\n",
    "\n",
    "**3Blue1Brown - Neural Networks:**\n",
    "- [Neural Networks Chapter 1](https://www.youtube.com/watch?v=aircAruvnKk)\n",
    "- [Neural Networks Chapter 2](https://www.youtube.com/watch?v=IHq1t7NxS8k)\n",
    "- [Neural Networks Chapter 3](https://www.youtube.com/watch?v=aircAruvnKk)\n",
    "\n",
    "**Medisinsk AI og Forklarbar AI:**\n",
    "- **S√∏k p√• YouTube**: \"Explainable AI in Healthcare\"\n",
    "- **S√∏k p√• YouTube**: \"Interpretable Machine Learning\"\n",
    "- **S√∏k p√• YouTube**: \"Grad-CAM Explained\"\n",
    "- **S√∏k p√• YouTube**: \"Medical AI Ethics\"\n",
    "- **S√∏k p√• YouTube**: \"Deep Learning for Medical Imaging\"\n",
    "\n",
    "\n",
    "### üõ†Ô∏è Praktiske Ressurser\n",
    "\n",
    "**Datasett:**\n",
    "- **MedMNIST**: [medmnist.com](https://medmnist.com/)\n",
    "- **MIMIC-CXR**: [physionet.org](https://physionet.org/)\n",
    "- **NIH Chest X-ray**: [nih.gov](https://www.nih.gov/)\n",
    "\n",
    "**Verkt√∏y:**\n",
    "- **MONAI**: Medical imaging AI framework\n",
    "- **nnU-Net**: State-of-the-art segmentation\n",
    "- **Grad-CAM**: Explainable AI\n",
    "\n",
    "**Hjelp med kode:**\n",
    "- **Stack Overflow:** [stackoverflow.com](https://stackoverflow.com/)\n",
    "- **PyTorch Forum:** [discuss.pytorch.org](https://discuss.pytorch.org/)\n",
    "- **MONAI Forum:** [github.com/Project-MONAI/MONAI/discussions](https://github.com/Project-MONAI/MONAI/discussions)\n",
    "\n",
    "**Konferanser:**\n",
    "- **MICCAI**: Medical Image Computing and Computer Assisted Intervention\n",
    "- **SPIE Medical Imaging**: Medical imaging conference\n",
    "- **RSNA**: Radiological Society of North America"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üöÄ Veien Videre\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üí° Oppgaver og Refleksjoner\n",
    "\n",
    "### üìù  Oppgave 1: Modell-sammenligning\n",
    "\n",
    "**Oppgave:**\n",
    "Sammenlign v√•r CNN-modell med en pretrent modell (ResNet, VGG, etc.) p√• samme datasett.\n",
    "\n",
    "**Sp√∏rsm√•l √• reflektere over:**\n",
    "- Hvilken modell presterer best?\n",
    "- Hvorfor er pretrente modeller ofte bedre?\n",
    "- N√•r er det lurt √• bygge fra bunnen av?\n",
    "\n",
    "### üìù Oppgave 2: Medisinsk datasett\n",
    "\n",
    "**Oppgave:**\n",
    "Last ned et medisinsk datasett (f.eks. MedMNIST) og tren en modell p√• det.\n",
    "\n",
    "**Sp√∏rsm√•l √• reflektere over:**\n",
    "- Hvordan skiller medisinske bilder seg fra naturlige?\n",
    "- Hvilke utfordringer m√∏ter du?\n",
    "- Hvordan kan du forbedre modellen?\n",
    "\n",
    "### üìù  Oppgave 3: Etiske betraktninger\n",
    "\n",
    "**Oppgave:**\n",
    "Diskuter etiske aspekter ved AI (CNN) i medisin.\n",
    "\n",
    "**Sp√∏rsm√•l √• reflektere over:**\n",
    "- Hvem er ansvarlig hvis AI-en gj√∏r feil?\n",
    "- Hvordan sikrer vi at AI-en er rettferdig?\n",
    "- Hvordan balanserer vi automatisering og menneskelig kontroll?\n",
    "\n",
    "### üìù  Oppgave 4: Veien videre\n",
    "\n",
    "**Sp√∏rsm√•l √• reflektere over:**\n",
    "- Hvilke ferdigheter trenger du?\n",
    "- Hvilke ressurser kan du bruke?\n",
    "- Hvordan kan du praktisere?\n",
    "- Hvilke nettverk kan du bygge?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üéâ Konklusjon\n",
    "\n",
    "###  Hva har vi oppn√•dd?\n",
    "\n",
    "Vi har:\n",
    "- **Bygget** en CNN-modell fra bunnen av\n",
    "- **Trent** modellen p√• blomsterdata\n",
    "- **Evalueret** modellens ytelse\n",
    "- **Forst√•tt /f√•tt insikt i** modellens beslutningsprosess\n",
    "- **Sammenlignet** naturlige og medisinske bilder\n",
    "- **Utforsket** kunnskapsstoff om CNN i helse\n",
    "\n",
    "###  Hva betyr dette for fremtiden?\n",
    "\n",
    "**AI i medisin er ikke lenger science fiction** - det er en realitet som:\n",
    "- **Kan forbedre** diagnostikk og behandling\n",
    "- **Kan redusere** menneskelige feil\n",
    "- **Kan demokratisere** medisinsk ekspertise\n",
    "- **Vil transformere** helsevesenet\n",
    "\n",
    "###  Din rolle\n",
    "\n",
    "Du er n√• en del av denne transformasjonen. Du har:\n",
    "- **Teknisk innsikt** i CNN og dypl√¶ring\n",
    "- **Bedre forst√•else** av medisinske AI-applikasjoner\n",
    "- **√òkt etisk bevissthet** om AI i helse\n",
    "- **Praktisk erfaring** med modell-utvikling\n",
    "\n",
    "---\n",
    "\n",
    "**Takk for at du fulgte med p√• denne reisen i bruk av CNN fra natur til medisin!** üöÄ\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üéì‚ú® Men vi vil gi deg litt mer ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üè• fastMONAI - Bergen-basert Medisinsk AI\n",
    "\n",
    "### üåü Hva er fastMONAI?\n",
    "\n",
    "**fastMONAI** er et norsk, open-source bibliotek for medisinsk AI som er utviklet ved **Mohn Medical Imaging and Visualization Centre** / **Haukeland universitetssykehus**. <br>\n",
    "Det bygger videre p√• fastai, MONAI, TorchIO og Imagedata, og forenkler bruken av state-of-the-art dypl√¶rings-teknikker i 3D medisinsk bildeanalyse.\n",
    "\n",
    "**Hovedm√•l:**\n",
    "- **Forenkle** bruken av avanserte dypl√¶rings-teknikker\n",
    "- **L√∏se** klassifikasjon-, regresjon- og segmentering-oppgaver\n",
    "- **Tilby** funksjonalitet for data loading, preprosessering, trening og resultat-tolkning\n",
    "\n",
    "### ‚ùì Hvorfor fastMONAI?\n",
    "\n",
    "**Fordeler:**\n",
    "- **Low-code tiln√¶rming**: Enklere API enn standard MONAI\n",
    "- **Norsk utvikling**: Utviklet av norske forskere (Satheshkumar Kaliyugarasan og Alexander S. Lundervold)\n",
    "- **Medisinsk fokus**: Spesialisert for 3D medisinske bilder\n",
    "- **Open source**: Gratis og tilgjengelig for alle\n",
    "- **Interaktive notebooks**: Dokumentasjon som Jupyter notebooks\n",
    "\n",
    "### üìã Krav\n",
    "\n",
    "- **Python:** 3.10, 3.11, eller 3.12 (Python 3.11 anbefalt)\n",
    "- **GPU:** CUDA-kompatibel GPU anbefalt for trening (CPU st√∏ttet for inferens)\n",
    "\n",
    "### üõ†Ô∏è Installasjon\n",
    "\n",
    "**Anbefalt milj√∏-oppsett:**\n",
    "```bash\n",
    "# Opprett conda-milj√∏\n",
    "conda create -n fastmonai python=3.11\n",
    "conda activate fastmonai\n",
    "\n",
    "# Installer fastMONAI\n",
    "pip install fastMONAI\n",
    "```\n",
    "\n",
    "**Utviklingsinstallasjon:**\n",
    "```bash\n",
    "# Klon repository\n",
    "git clone https://github.com/MMIV-ML/fastMONAI\n",
    "cd fastMONAI\n",
    "\n",
    "# Opprett utviklingsmilj√∏\n",
    "conda create -n fastmonai-dev python=3.11\n",
    "conda activate fastmonai-dev\n",
    "\n",
    "# Installer i utviklingsmodus\n",
    "pip install -e '.[dev]'\n",
    "```\n",
    "\n",
    "### üöÄ Kom i gang\n",
    "\n",
    "**Best m√•te √• komme i gang:**\n",
    "1. **Les artikkelen**: [fastMONAI: A low-code deep learning library for medical image analysis](https://www.sciencedirect.com/science/article/pii/S2665963823001203)\n",
    "2. **Se video-tutorial**: [Getting started video](https://fastmonai.no/#getting-started)\n",
    "3. **Pr√∏v notebooks**: Interaktive eksempler for ulike oppgaver\n",
    "\n",
    "###  Interaktive Tutorials\n",
    "\n",
    "| Notebook | Beskrivelse | 1-Click |\n",
    "|----------|-------------|---------|\n",
    "| [**Klassifikasjon**](https://nbviewer.org/github/MMIV-ML/fastMONAI/blob/main/nbs/10a_tutorial_classification.ipynb) | Bin√¶r klassifikasjon basert p√• MRI-data | [Google Colab](https://colab.research.google.com/github/MMIV-ML/fastMONAI/blob/main/nbs/10a_tutorial_classification.ipynb) |\n",
    "| [**Regresjon**](https://nbviewer.org/github/MMIV-ML/fastMONAI/blob/main/nbs/10b_tutorial_regression.ipynb) | Predikere alder fra MRI-scanning (\"brain age\") | [Google Colab](https://colab.research.google.com/github/MMIV-ML/fastMONAI/blob/main/nbs/10b_tutorial_regression.ipynb) |\n",
    "| [**Bin√¶r segmentering**](https://nbviewer.org/github/MMIV-ML/fastMONAI/blob/main/nbs/10c_tutorial_binary_segmentation.ipynb) | Ekstraher venstre atriale fra kardiak MRI | [Google Colab](https://colab.research.google.com/github/MMIV-ML/fastMONAI/blob/main/nbs/10c_tutorial_binary_segmentation.ipynb) |\n",
    "| [**Multi-klasse segmentering**](https://nbviewer.org/github/MMIV-ML/fastMONAI/blob/main/nbs/10d_tutorial_multiclass_segmentation.ipynb) | Hjerne-tumor segmentering fra multimodal MRI | [Google Colab](https://colab.research.google.com/github/MMIV-ML/fastMONAI/blob/main/nbs/10d_tutorial_multiclass_segmentation.ipynb) |\n",
    "\n",
    "\n",
    "\n",
    "### üìñ Ressurser og Dokumentasjon\n",
    "\n",
    "**Offisiell dokumentasjon:**\n",
    "- **Hjemmeside**: [fastmonai.no](https://fastmonai.no)\n",
    "- **GitHub**: [github.com/MMIV-ML/fastMONAI](https://github.com/MMIV-ML/fastMONAI)\n",
    "- **PyPI**: [pypi.org/project/fastMONAI](https://pypi.org/project/fastMONAI)\n",
    "\n",
    "**Forskningsartikkel:**\n",
    "```bibtex\n",
    "@article{KALIYUGARASAN2023100583,\n",
    "title = {fastMONAI: A low-code deep learning library for medical image analysis},\n",
    "journal = {Software Impacts},\n",
    "pages = {100583},\n",
    "year = {2023},\n",
    "issn = {2665-9638},\n",
    "doi = {https://doi.org/10.1016/j.simpa.2023.100583},\n",
    "url = {https://www.sciencedirect.com/science/article/pii/S2665963823001203},\n",
    "author = {Satheshkumar Kaliyugarasan and Alexander S. Lundervold},\n",
    "keywords = {Deep learning, Medical imaging, Radiology}\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "**fastMONAI er et produkt av norsk AI-forskning og -utvikling og et godt verkt√∏y for √• komme i gang med bilde-basert medisinsk AI i en norsk kontekst**\n",
    "\n",
    "**Kilder:**\n",
    "- [fastmonai.no](https://fastmonai.no/#getting-started)\n",
    "- [GitHub Repository](https://github.com/MMIV-ML/fastMONAI)\n",
    "- [Forskningsartikkel](https://www.sciencedirect.com/science/article/pii/S2665963823001203)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmed219-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
