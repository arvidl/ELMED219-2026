{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arvidl/ELMED219-2026/blob/main/Lab3-GenAI-LLM/notebooks/06-ai-etikk-medisin.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI-etikk i Medisin\n",
    "\n",
    "**ELMED219 / BMED365 - Lab 3**\n",
    "\n",
    "---\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Etter denne notebooken skal du kunne:\n",
    "- Identifisere etiske utfordringer med AI i helsevesenet\n",
    "- Forklare ulike typer bias i medisinske AI-systemer\n",
    "- Diskutere personvernhensyn ved bruk av AI på helsedata\n",
    "- Beskrive relevante reguleringer (EU AI Act)\n",
    "- Reflektere over ansvar og transparens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innhold\n",
    "\n",
    "1. [Etiske utfordringer](#1-etiske-utfordringer)\n",
    "2. [Bias i medisinsk AI](#2-bias-i-medisinsk-ai)\n",
    "3. [Personvern og datasikkerhet](#3-personvern-og-datasikkerhet)\n",
    "4. [Regulering og EU AI Act](#4-regulering-og-eu-ai-act)\n",
    "5. [Ansvar og beslutningstaking](#5-ansvar-og-beslutningstaking)\n",
    "6. [Beste praksis](#6-beste-praksis)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Etiske utfordringer\n",
    "\n",
    "AI i helsevesenet reiser fundamentale etiske spørsmål som berører de fire prinsippene i medisinsk etikk:\n",
    "\n",
    "| Prinsipp | AI-utfordring |\n",
    "|----------|---------------|\n",
    "| **Autonomi** | Påvirker AI pasientens frie valg? Forstår pasienten at AI brukes? |\n",
    "| **Velgjørenhet** | Gir AI faktisk bedre utfall for pasienten? |\n",
    "| **Ikke-skade** | Kan AI-feil føre til skade? Hvem er ansvarlig? |\n",
    "| **Rettferdighet** | Er AI rettferdig på tvers av pasientgrupper? |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eksempler på etiske dilemmaer\n",
    "\n",
    "**Case 1: Ressursallokering**\n",
    "> En AI predikerer at pasient A har 80% sjanse for å overleve intensivbehandling, mens pasient B har 40%. Skal AI-prediksjonen avgjøre hvem som får intensivplass?\n",
    "\n",
    "**Case 2: Autonomi vs. sikkerhet**\n",
    "> En pasient nekter behandling basert på AI-anbefaling, men ønsker behandling som AI fraråder. Hvordan vektes pasientens autonomi mot AI-anbefalingen?\n",
    "\n",
    "**Case 3: Transparens**\n",
    "> En kompleks AI-modell gir bedre diagnoser enn leger, men kan ikke forklare hvorfor. Skal den brukes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ETISK SJEKKLISTE FOR MEDISINSK AI\n",
      "==================================================\n",
      "\n",
      "Transparens:\n",
      "  □ Er det tydelig for pasienter at AI brukes?\n",
      "  □ Kan beslutninger forklares?\n",
      "  □ Er treningsdata dokumentert?\n",
      "\n",
      "Rettferdighet:\n",
      "  □ Er modellen testet på ulike populasjoner?\n",
      "  □ Er det kjente bias i dataene?\n",
      "  □ Overvåkes ytelse på tvers av grupper?\n",
      "\n",
      "Personvern:\n",
      "  □ Hvordan håndteres pasientdata?\n",
      "  □ Er samtykke innhentet?\n",
      "  □ Kan data de-anonymiseres?\n",
      "\n",
      "Ansvar:\n",
      "  □ Hvem er ansvarlig ved feil?\n",
      "  □ Finnes det menneskelig overstyring?\n",
      "  □ Hvordan logges beslutninger?\n",
      "\n",
      "Sikkerhet:\n",
      "  □ Hva skjer hvis systemet feiler?\n",
      "  □ Er det backup-prosedyrer?\n",
      "  □ Hvordan oppdateres modellen?\n"
     ]
    }
   ],
   "source": [
    "# Rammeverk for etisk vurdering av AI-systemer\n",
    "\n",
    "def etisk_sjekkliste(ai_system):\n",
    "    \"\"\"\n",
    "    Sjekkliste for etisk vurdering av et medisinsk AI-system.\n",
    "    \"\"\"\n",
    "    sjekkliste = {\n",
    "        \"Transparens\": [\n",
    "            \"Er det tydelig for pasienter at AI brukes?\",\n",
    "            \"Kan beslutninger forklares?\",\n",
    "            \"Er treningsdata dokumentert?\"\n",
    "        ],\n",
    "        \"Rettferdighet\": [\n",
    "            \"Er modellen testet på ulike populasjoner?\",\n",
    "            \"Er det kjente bias i dataene?\",\n",
    "            \"Overvåkes ytelse på tvers av grupper?\"\n",
    "        ],\n",
    "        \"Personvern\": [\n",
    "            \"Hvordan håndteres pasientdata?\",\n",
    "            \"Er samtykke innhentet?\",\n",
    "            \"Kan data de-anonymiseres?\"\n",
    "        ],\n",
    "        \"Ansvar\": [\n",
    "            \"Hvem er ansvarlig ved feil?\",\n",
    "            \"Finnes det menneskelig overstyring?\",\n",
    "            \"Hvordan logges beslutninger?\"\n",
    "        ],\n",
    "        \"Sikkerhet\": [\n",
    "            \"Hva skjer hvis systemet feiler?\",\n",
    "            \"Er det backup-prosedyrer?\",\n",
    "            \"Hvordan oppdateres modellen?\"\n",
    "        ]\n",
    "    }\n",
    "    return sjekkliste\n",
    "\n",
    "sjekkliste = etisk_sjekkliste(\"Diagnosestøtte-AI\")\n",
    "\n",
    "print(\"ETISK SJEKKLISTE FOR MEDISINSK AI\")\n",
    "print(\"=\" * 50)\n",
    "for kategori, sporsmal in sjekkliste.items():\n",
    "    print(f\"\\n{kategori}:\")\n",
    "    for sp in sporsmal:\n",
    "        print(f\"  □ {sp}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. Bias i medisinsk AI\n",
    "\n",
    "Bias i AI-systemer kan føre til systematisk urettferdig behandling av pasientgrupper.\n",
    "\n",
    "### Typer bias\n",
    "\n",
    "| Type | Beskrivelse | Eksempel |\n",
    "|------|-------------|----------|\n",
    "| **Historisk bias** | Treningsdata reflekterer tidligere urettferdighet | Kvinner underdiagnostisert for hjertesykdom |\n",
    "| **Representasjonsbias** | Noen grupper underrepresentert i data | Lite data fra ikke-vestlige populasjoner |\n",
    "| **Målebias** | Ulike målemetoder for ulike grupper | Hudfarve påvirker pulsoksymeter |\n",
    "| **Aggregasjonsbias** | Samme modell for alle, ignorerer subgrupper | Én diabetes-modell for alle aldersgrupper |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax. Perhaps you forgot a comma? (2984086627.py, line 49)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[2], line 49\u001b[0;36m\u001b[0m\n\u001b[0;31m    print(f\"  - Dette betyr at flere i gruppe B får feilaktig \"friskmelding\"\")\u001b[0m\n\u001b[0m          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax. Perhaps you forgot a comma?\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Demonstrasjon av bias i en hypotetisk AI-modell\n",
    "\n",
    "def simuler_bias_eksempel():\n",
    "    \"\"\"\n",
    "    Simulerer en AI-modell med ulik ytelse på forskjellige grupper.\n",
    "    Basert på virkelige observasjoner fra medisinsk AI-forskning.\n",
    "    \"\"\"\n",
    "    grupper = ['Gruppe A\\n(majoritetsgruppe)', 'Gruppe B\\n(minoritetsgruppe)']\n",
    "    \n",
    "    # Simulerte ytelsesmål\n",
    "    sensitivitet = [0.92, 0.71]  # Hvor godt modellen fanger opp sykdom\n",
    "    spesifisitet = [0.88, 0.82]  # Hvor godt modellen utelukker friske\n",
    "    \n",
    "    return grupper, sensitivitet, spesifisitet\n",
    "\n",
    "grupper, sens, spec = simuler_bias_eksempel()\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "\n",
    "x = np.arange(len(grupper))\n",
    "width = 0.35\n",
    "\n",
    "bars1 = ax.bar(x - width/2, sens, width, label='Sensitivitet', color='steelblue')\n",
    "bars2 = ax.bar(x + width/2, spec, width, label='Spesifisitet', color='coral')\n",
    "\n",
    "ax.set_ylabel('Score')\n",
    "ax.set_title('Bias i AI-modell: Ulik ytelse på forskjellige grupper')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(grupper)\n",
    "ax.legend()\n",
    "ax.set_ylim(0, 1)\n",
    "\n",
    "# Legg til verdier på søylene\n",
    "for bar in bars1 + bars2:\n",
    "    height = bar.get_height()\n",
    "    ax.annotate(f'{height:.0%}',\n",
    "                xy=(bar.get_x() + bar.get_width() / 2, height),\n",
    "                xytext=(0, 3), textcoords=\"offset points\",\n",
    "                ha='center', va='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nKonsekvens:\")\n",
    "print(f\"  - Gruppe B har {(sens[0]-sens[1])*100:.0f}% lavere sensitivitet\")\n",
    "print(f\"  - Dette betyr at flere i gruppe B får feilaktig \"friskmelding\"\")\n",
    "print(f\"  - Slike skjevheter kan forsterke eksisterende helseforskjeller\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Virkelige eksempler på bias\n",
    "\n",
    "1. **Hudkreft-deteksjon**: Modeller trent primært på lyshudet populasjon presterer dårligere på mørkere hud\n",
    "\n",
    "2. **Pulsoksymeter**: Overestimerer oksygenmetning hos mørkhudede pasienter\n",
    "\n",
    "3. **Smertebehandling**: Historisk undervurdering av smerte hos minoriteter reflekteres i data\n",
    "\n",
    "4. **Kjønnsforskjeller**: Symptomer på hjertesykdom presenterer seg ulikt hos kvinner, men modeller trenes ofte på mannsdominerte datasett"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Personvern og datasikkerhet\n",
    "\n",
    "Helsedata er blant de mest sensitive personopplysningene og krever særlig beskyttelse.\n",
    "\n",
    "### GDPR og helsedata\n",
    "\n",
    "Under GDPR er helsedata en \"særlig kategori\" som krever:\n",
    "\n",
    "- Eksplisitt samtykke eller annen lovlig basis\n",
    "- Strenge sikkerhetstiltak\n",
    "- Dataminimering (kun nødvendige data)\n",
    "- Rett til innsyn og sletting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PERSONVERN-RISIKOVURDERING\n",
      "==================================================\n",
      "\n",
      "AI KJØRER I EKSTERN SKY-TJENESTE\n",
      "----------------------------------------\n",
      "Risikoer:\n",
      "  ⚠ Data sendes ut av organisasjonen\n",
      "  ⚠ Tredjepartsleverandør har tilgang\n",
      "  ⚠ Usikker hvor data lagres geografisk\n",
      "  ⚠ Data kan brukes til modelltrening\n",
      "Tiltak:\n",
      "  ✓ Databehandleravtale (DBA)\n",
      "  ✓ Verifiser EU-lagring\n",
      "  ✓ Kryptering i transit og hvile\n",
      "  ✓ Opt-out fra treningsdata\n",
      "\n",
      "AI KJØRER LOKALT PÅ SYKEHUSINFRASTRUKTUR\n",
      "----------------------------------------\n",
      "Risikoer:\n",
      "  ⚠ Intern tilgangsstyring\n",
      "  ⚠ Logging og sporbarhet\n",
      "  ⚠ Oppdatering og vedlikehold\n",
      "Tiltak:\n",
      "  ✓ Rollebasert tilgang\n",
      "  ✓ Audit-logging\n",
      "  ✓ Sikker oppdateringsrutine\n"
     ]
    }
   ],
   "source": [
    "# Personvern-risikovurdering\n",
    "\n",
    "def personvern_risiko(scenario):\n",
    "    \"\"\"\n",
    "    Vurder personvernrisiko for et AI-scenario.\n",
    "    \"\"\"\n",
    "    risikoer = {\n",
    "        \"sky_tjeneste\": {\n",
    "            \"beskrivelse\": \"AI kjører i ekstern sky-tjeneste\",\n",
    "            \"risikoer\": [\n",
    "                \"Data sendes ut av organisasjonen\",\n",
    "                \"Tredjepartsleverandør har tilgang\",\n",
    "                \"Usikker hvor data lagres geografisk\",\n",
    "                \"Data kan brukes til modelltrening\"\n",
    "            ],\n",
    "            \"tiltak\": [\n",
    "                \"Databehandleravtale (DBA)\",\n",
    "                \"Verifiser EU-lagring\",\n",
    "                \"Kryptering i transit og hvile\",\n",
    "                \"Opt-out fra treningsdata\"\n",
    "            ]\n",
    "        },\n",
    "        \"lokal_modell\": {\n",
    "            \"beskrivelse\": \"AI kjører lokalt på sykehusinfrastruktur\",\n",
    "            \"risikoer\": [\n",
    "                \"Intern tilgangsstyring\",\n",
    "                \"Logging og sporbarhet\",\n",
    "                \"Oppdatering og vedlikehold\"\n",
    "            ],\n",
    "            \"tiltak\": [\n",
    "                \"Rollebasert tilgang\",\n",
    "                \"Audit-logging\",\n",
    "                \"Sikker oppdateringsrutine\"\n",
    "            ]\n",
    "        }\n",
    "    }\n",
    "    return risikoer.get(scenario, {})\n",
    "\n",
    "print(\"PERSONVERN-RISIKOVURDERING\")\n",
    "print(\"=\" * 50)\n",
    "\n",
    "for scenario in [\"sky_tjeneste\", \"lokal_modell\"]:\n",
    "    info = personvern_risiko(scenario)\n",
    "    print(f\"\\n{info['beskrivelse'].upper()}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(\"Risikoer:\")\n",
    "    for r in info['risikoer']:\n",
    "        print(f\"  ⚠ {r}\")\n",
    "    print(\"Tiltak:\")\n",
    "    for t in info['tiltak']:\n",
    "        print(f\"  ✓ {t}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Spesielle hensyn for LLM-er\n",
    "\n",
    "Store språkmodeller (LLM) reiser unike personvernspørsmål:\n",
    "\n",
    "1. **Memorisering**: LLM-er kan huske og gjenta sensitiv informasjon fra trening\n",
    "2. **Prompt-injeksjon**: Ondsinnede prompts kan prøve å trekke ut sensitiv data\n",
    "3. **Treningsdata**: Usikkerhet om hva modellen er trent på\n",
    "4. **API-logging**: Sky-leverandører kan logge alle prompts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Regulering og EU AI Act\n",
    "\n",
    "EU AI Act (2024) er verdens første omfattende AI-regulering.\n",
    "\n",
    "### Risikobasert tilnærming\n",
    "\n",
    "```\n",
    "┌─────────────────────────────────────────────────────────┐\n",
    "│  FORBUDT                                                │\n",
    "│  Sosial scoring, manipulative AI, biometrisk ID i      │\n",
    "│  offentlig rom                                          │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│  HØY RISIKO                                             │\n",
    "│  Medisinsk utstyr, kritisk infrastruktur,              │\n",
    "│  rekruttering, utdanning                                │\n",
    "│  → Strenge krav til dokumentasjon, testing, tilsyn     │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│  BEGRENSET RISIKO                                       │\n",
    "│  Chatbots, deepfakes                                    │\n",
    "│  → Transparenskrav (\"Du snakker med AI\")               │\n",
    "├─────────────────────────────────────────────────────────┤\n",
    "│  MINIMAL RISIKO                                         │\n",
    "│  De fleste AI-systemer                                  │\n",
    "│  → Ingen spesielle krav                                 │\n",
    "└─────────────────────────────────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Krav til høyrisiko-AI (inkl. medisinsk)\n",
    "\n",
    "- Risikovurdering og -styring\n",
    "- Datakvalitetsstyring\n",
    "- Teknisk dokumentasjon\n",
    "- Logging og sporbarhet\n",
    "- Transparens overfor brukere\n",
    "- Menneskelig tilsyn\n",
    "- Robusthet og cybersikkerhet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Ansvar og beslutningstaking\n",
    "\n",
    "### Hvem er ansvarlig?\n",
    "\n",
    "Ved AI-feil i helsevesenet er ansvarsfordelingen kompleks:\n",
    "\n",
    "| Aktør | Potensielt ansvar |\n",
    "|-------|-------------------|\n",
    "| **Legen** | Klinisk beslutning, bruk av AI som verktøy |\n",
    "| **Sykehuset** | Valg av system, implementering, opplæring |\n",
    "| **AI-leverandøren** | Produktansvar, dokumentasjon |\n",
    "| **Dataansvarlig** | Datakvalitet, personvern |\n",
    "\n",
    "### Human-in-the-loop\n",
    "\n",
    "Et viktig prinsipp er at mennesker alltid skal kunne:\n",
    "- Overstyre AI-beslutninger\n",
    "- Forstå grunnlaget for anbefalinger\n",
    "- Velge å ikke bruke AI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Beste praksis\n",
    "\n",
    "### Etisk bruk av AI i helsevesenet\n",
    "\n",
    "**Før implementering:**\n",
    "- Gjennomfør etisk vurdering\n",
    "- Test for bias på ulike populasjoner\n",
    "- Etabler klare ansvarslinjer\n",
    "- Sikre personvernkomplians\n",
    "\n",
    "**Under bruk:**\n",
    "- Gi opplæring til brukere\n",
    "- Overvåk ytelse kontinuerlig\n",
    "- Logg alle AI-beslutninger\n",
    "- Ha rutiner for menneskelig overstyring\n",
    "\n",
    "**Kommunikasjon:**\n",
    "- Informer pasienter om AI-bruk\n",
    "- Vær transparent om begrensninger\n",
    "- Ikke overselg AI-kapabiliteter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oppsummering\n",
    "\n",
    "### Hovedpunkter\n",
    "\n",
    "1. **Etiske prinsipper** (autonomi, velgjørenhet, ikke-skade, rettferdighet) gjelder også for AI\n",
    "2. **Bias** kan forsterke eksisterende helseforskjeller hvis ikke adressert\n",
    "3. **Personvern** krever særlige tiltak for helsedata, spesielt ved sky-tjenester\n",
    "4. **EU AI Act** klassifiserer medisinsk AI som høyrisiko med strenge krav\n",
    "5. **Ansvar** er delt mellom mange aktører, men legen beholder klinisk ansvar\n",
    "\n",
    "### Refleksjonsoppgaver\n",
    "\n",
    "1. Hvordan ville du forklart til en pasient at AI brukes i deres behandling?\n",
    "2. Hvilke tiltak ville du innført for å oppdage bias i en AI-modell?\n",
    "3. Bør leger kunne stilles til ansvar for AI-feil de ikke kunne forutse?\n",
    "\n",
    "---\n",
    "\n",
    "*Neste notebook: [07 - Trustworthy AI](07-trustworthy-ai.ipynb)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmed219-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
