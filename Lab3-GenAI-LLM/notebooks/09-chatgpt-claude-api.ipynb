{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/arvidl/ELMED219-2026/blob/main/Lab3-GenAI-LLM/notebooks/09-chatgpt-claude-api.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ChatGPT og Claude API - Praktisk Integrasjon\n",
    "\n",
    "**ELMED219 / BMED365 - Lab 3**\n",
    "\n",
    "---\n",
    "\n",
    "> **Merk**: Denne notebooken er valgfri og krever API-nøkler fra OpenAI og/eller Anthropic. Den er beregnet på studenter som ønsker å eksperimentere med programmatisk bruk av LLM-er.\n",
    "\n",
    "## Læringsmål\n",
    "\n",
    "Etter denne notebooken skal du kunne:\n",
    "- Sette opp og bruke OpenAI (ChatGPT) og Anthropic (Claude) APIer\n",
    "- Implementere feilhåndtering og rate limiting\n",
    "- Bygge en enkel medisinsk assistent-funksjon\n",
    "- Forstå beste praksis for API-bruk i medisinske kontekster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Innhold\n",
    "\n",
    "1. [Oppsett og konfigurasjon](#1-oppsett-og-konfigurasjon)\n",
    "2. [OpenAI API (ChatGPT)](#2-openai-api-chatgpt)\n",
    "3. [Anthropic API (Claude)](#3-anthropic-api-claude)\n",
    "4. [Feilhåndtering](#4-feilhåndtering)\n",
    "5. [Praktiske eksempler](#5-praktiske-eksempler)\n",
    "6. [Sikkerhetshensyn](#6-sikkerhetshensyn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 1. Oppsett og konfigurasjon\n",
    "\n",
    "### Forutsetninger\n",
    "\n",
    "1. API-nøkkel fra [OpenAI](https://platform.openai.com/api-keys) og/eller [Anthropic](https://console.anthropic.com/)\n",
    "2. Python-pakker: `openai`, `anthropic`\n",
    "\n",
    "### Beste praksis for API-nøkler\n",
    "\n",
    "**Aldri** hardkod API-nøkler i kode. Bruk miljøvariabler:\n",
    "\n",
    "```bash\n",
    "# I terminal:\n",
    "export OPENAI_API_KEY=\"sk-...\"\n",
    "export ANTHROPIC_API_KEY=\"sk-ant-...\"\n",
    "```\n",
    "\n",
    "Eller en `.env`-fil (som IKKE skal committes til git)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Miljøvariabler lastet fra .env\n",
      "\n",
      "API-tilgjengelighet:\n",
      "  OpenAI (ChatGPT): Tilgjengelig\n",
      "  Anthropic (Claude): Ikke konfigurert\n"
     ]
    }
   ],
   "source": [
    "# Installer nødvendige pakker (kjør om nødvendig)\n",
    "# !pip install openai anthropic python-dotenv\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "# Sjekk om vi er i Colab\n",
    "IN_COLAB = 'google.colab' in sys.modules\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"Kjører i Google Colab\")\n",
    "    !pip install openai anthropic python-dotenv --quiet\n",
    "\n",
    "# Last miljøvariabler fra .env hvis den finnes\n",
    "try:\n",
    "    from dotenv import load_dotenv\n",
    "    load_dotenv()\n",
    "    print(\"Miljøvariabler lastet fra .env\")\n",
    "except ImportError:\n",
    "    print(\"python-dotenv ikke installert - bruker eksisterende miljøvariabler\")\n",
    "\n",
    "# Sjekk tilgjengelige APIer\n",
    "OPENAI_AVAILABLE = bool(os.getenv(\"OPENAI_API_KEY\"))\n",
    "ANTHROPIC_AVAILABLE = bool(os.getenv(\"ANTHROPIC_API_KEY\"))\n",
    "\n",
    "print(f\"\\nAPI-tilgjengelighet:\")\n",
    "print(f\"  OpenAI (ChatGPT): {'Tilgjengelig' if OPENAI_AVAILABLE else 'Ikke konfigurert'}\")\n",
    "print(f\"  Anthropic (Claude): {'Tilgjengelig' if ANTHROPIC_AVAILABLE else 'Ikke konfigurert'}\")\n",
    "\n",
    "if not (OPENAI_AVAILABLE or ANTHROPIC_AVAILABLE):\n",
    "    print(\"\\n⚠️  Ingen API-nøkler funnet.\")\n",
    "    print(\"   Eksemplene vil vise simulerte responser.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 2. OpenAI API (ChatGPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respons:\n",
      "HbA1c måler gjennomsnittlig blodsukkernivå over de siste 2-3 månedene.\n"
     ]
    }
   ],
   "source": [
    "from typing import Optional\n",
    "\n",
    "def chat_with_gpt(prompt: str, \n",
    "                  model: str = \"gpt-3.5-turbo\",\n",
    "                  temperature: float = 0.7,\n",
    "                  system_prompt: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Send en melding til ChatGPT og få respons.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Brukerens melding\n",
    "        model: GPT-modell (gpt-3.5-turbo, gpt-4, etc.)\n",
    "        temperature: 0-2, hvor 0 er deterministisk\n",
    "        system_prompt: Valgfri system-instruksjon\n",
    "    \n",
    "    Returns:\n",
    "        Modellens respons\n",
    "    \"\"\"\n",
    "    if not OPENAI_AVAILABLE:\n",
    "        return f\"[SIMULERT RESPONS]\\nDette er en simulert respons for: {prompt[:100]}...\"\n",
    "    \n",
    "    try:\n",
    "        from openai import OpenAI\n",
    "        client = OpenAI()\n",
    "        \n",
    "        messages = []\n",
    "        if system_prompt:\n",
    "            messages.append({\"role\": \"system\", \"content\": system_prompt})\n",
    "        messages.append({\"role\": \"user\", \"content\": prompt})\n",
    "        \n",
    "        response = client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=messages,\n",
    "            temperature=temperature\n",
    "        )\n",
    "        \n",
    "        return response.choices[0].message.content\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Feil ved API-kall: {e}\"\n",
    "\n",
    "# Test\n",
    "respons = chat_with_gpt(\n",
    "    \"Forklar kort hva HbA1c måler.\",\n",
    "    temperature=0.3,\n",
    "    system_prompt=\"Du er en hjelpsom medisinsk assistent. Svar kort og presist.\"\n",
    ")\n",
    "print(\"Respons:\")\n",
    "print(respons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 3. Anthropic API (Claude)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Respons:\n",
      "[SIMULERT RESPONS]\n",
      "Dette er en simulert respons for: Hva er forskjellen mellom Type 1 og Type 2 diabetes?...\n"
     ]
    }
   ],
   "source": [
    "def chat_with_claude(prompt: str,\n",
    "                     model: str = \"claude-3-sonnet-20240229\",\n",
    "                     temperature: float = 0.7,\n",
    "                     system_prompt: str = None) -> str:\n",
    "    \"\"\"\n",
    "    Send en melding til Claude og få respons.\n",
    "    \n",
    "    Args:\n",
    "        prompt: Brukerens melding\n",
    "        model: Claude-modell (claude-3-sonnet, claude-3-opus, etc.)\n",
    "        temperature: 0-1\n",
    "        system_prompt: Valgfri system-instruksjon\n",
    "    \n",
    "    Returns:\n",
    "        Modellens respons\n",
    "    \"\"\"\n",
    "    if not ANTHROPIC_AVAILABLE:\n",
    "        return f\"[SIMULERT RESPONS]\\nDette er en simulert respons for: {prompt[:100]}...\"\n",
    "    \n",
    "    try:\n",
    "        from anthropic import Anthropic\n",
    "        client = Anthropic()\n",
    "        \n",
    "        kwargs = {\n",
    "            \"model\": model,\n",
    "            \"max_tokens\": 1024,\n",
    "            \"temperature\": temperature,\n",
    "            \"messages\": [{\"role\": \"user\", \"content\": prompt}]\n",
    "        }\n",
    "        \n",
    "        if system_prompt:\n",
    "            kwargs[\"system\"] = system_prompt\n",
    "        \n",
    "        response = client.messages.create(**kwargs)\n",
    "        \n",
    "        return response.content[0].text\n",
    "        \n",
    "    except Exception as e:\n",
    "        return f\"Feil ved API-kall: {e}\"\n",
    "\n",
    "# Test\n",
    "respons = chat_with_claude(\n",
    "    \"Hva er forskjellen mellom Type 1 og Type 2 diabetes?\",\n",
    "    temperature=0.3,\n",
    "    system_prompt=\"Du er en medisinsk assistent. Forklar på en pasientvennlig måte.\"\n",
    ")\n",
    "print(\"Respons:\")\n",
    "print(respons)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 4. Feilhåndtering\n",
    "\n",
    "Ved programmatisk bruk av APIer er robust feilhåndtering kritisk."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobustAPIClient klar for bruk.\n",
      "Denne klassen håndterer rate limits og nettverksfeil automatisk.\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "class RobustAPIClient:\n",
    "    \"\"\"\n",
    "    Wrapper med retry-logikk og rate limiting.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, max_retries: int = 3, base_delay: float = 1.0):\n",
    "        self.max_retries = max_retries\n",
    "        self.base_delay = base_delay\n",
    "        self.last_call_time = 0\n",
    "        self.min_interval = 0.5  # Minimum tid mellom kall (sekunder)\n",
    "    \n",
    "    def _wait_if_needed(self):\n",
    "        \"\"\"Respekter rate limits.\"\"\"\n",
    "        elapsed = time.time() - self.last_call_time\n",
    "        if elapsed < self.min_interval:\n",
    "            time.sleep(self.min_interval - elapsed)\n",
    "        self.last_call_time = time.time()\n",
    "    \n",
    "    def call_api(self, func, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Utfør API-kall med retry-logikk.\n",
    "        \"\"\"\n",
    "        for attempt in range(self.max_retries):\n",
    "            try:\n",
    "                self._wait_if_needed()\n",
    "                return func(*args, **kwargs)\n",
    "                \n",
    "            except Exception as e:\n",
    "                error_msg = str(e)\n",
    "                \n",
    "                # Sjekk om det er en rate limit-feil\n",
    "                if \"rate_limit\" in error_msg.lower() or \"429\" in error_msg:\n",
    "                    wait_time = self.base_delay * (2 ** attempt)\n",
    "                    print(f\"Rate limit - venter {wait_time}s før retry {attempt + 1}/{self.max_retries}\")\n",
    "                    time.sleep(wait_time)\n",
    "                else:\n",
    "                    # Andre feil - returner feilmelding\n",
    "                    return f\"Feil etter {attempt + 1} forsøk: {e}\"\n",
    "        \n",
    "        return \"Maksimalt antall forsøk nådd\"\n",
    "\n",
    "# Eksempel på bruk\n",
    "print(\"RobustAPIClient klar for bruk.\")\n",
    "print(\"Denne klassen håndterer rate limits og nettverksfeil automatisk.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 5. Praktiske eksempler\n",
    "\n",
    "### Eksempel: Medisinsk assistent-funksjon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MEDISINSK ASSISTENT\n",
      "==================================================\n",
      "\n",
      "Svar:\n",
      "[Simulert svar for: Hva er vanlige bivirkninger av metformin?...]\n",
      "\n",
      "Dette er generell helseinformasjon. For personlig vurdering, kontakt helsepersonell.\n",
      "\n",
      "Advarsler:\n",
      "  ⚠️  Denne informasjonen erstatter ikke medisinsk rådgivning\n",
      "  ⚠️  Konsulter lege for personlig vurdering\n"
     ]
    }
   ],
   "source": [
    "def medisinsk_assistent(sporsmal: str, kontekst: str = None) -> dict:\n",
    "    \"\"\"\n",
    "    Medisinsk assistent med sikkerhetsinstruksjoner.\n",
    "    \n",
    "    Returns:\n",
    "        Dict med 'svar' og 'advarsler'\n",
    "    \"\"\"\n",
    "    \n",
    "    system_prompt = \"\"\"Du er en medisinsk informasjonsassistent.\n",
    "\n",
    "VIKTIGE REGLER:\n",
    "1. Gi kun generell helseinformasjon\n",
    "2. Aldri gi spesifikke diagnoser eller behandlingsanbefalinger\n",
    "3. Anbefal alltid å konsultere lege for personlige helsebekymringer\n",
    "4. Vær tydelig på begrensninger i din kunnskap\n",
    "5. Ved akutte symptomer: Anbefal umiddelbart å kontakte helsepersonell\n",
    "\n",
    "Svar på norsk, kort og presist.\"\"\"\n",
    "    \n",
    "    full_prompt = sporsmal\n",
    "    if kontekst:\n",
    "        full_prompt = f\"Kontekst: {kontekst}\\n\\nSpørsmål: {sporsmal}\"\n",
    "    \n",
    "    # Her ville vi normalt kalt API\n",
    "    # For demonstrasjon, simulerer vi responsen\n",
    "    \n",
    "    simulert_svar = {\n",
    "        \"svar\": f\"[Simulert svar for: {sporsmal[:50]}...]\\n\\n\" + \n",
    "                \"Dette er generell helseinformasjon. \" +\n",
    "                \"For personlig vurdering, kontakt helsepersonell.\",\n",
    "        \"advarsler\": [\n",
    "            \"Denne informasjonen erstatter ikke medisinsk rådgivning\",\n",
    "            \"Konsulter lege for personlig vurdering\"\n",
    "        ]\n",
    "    }\n",
    "    \n",
    "    return simulert_svar\n",
    "\n",
    "# Test\n",
    "resultat = medisinsk_assistent(\n",
    "    \"Hva er vanlige bivirkninger av metformin?\",\n",
    "    kontekst=\"Pasient med nyoppdaget diabetes type 2\"\n",
    ")\n",
    "\n",
    "print(\"MEDISINSK ASSISTENT\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"\\nSvar:\\n{resultat['svar']}\")\n",
    "print(f\"\\nAdvarsler:\")\n",
    "for adv in resultat['advarsler']:\n",
    "    print(f\"  ⚠️  {adv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## 6. Sikkerhetshensyn\n",
    "\n",
    "### Ved bruk av LLM-APIer i helsekontekst:\n",
    "\n",
    "**1. Personvern**\n",
    "- Aldri send reelle pasientdata til eksterne APIer uten godkjenning\n",
    "- Vurder lokale modeller (Ollama, etc.) for sensitiv data\n",
    "- Sjekk databehandleravtaler med API-leverandør\n",
    "\n",
    "**2. Hallusinering**\n",
    "- LLM-er kan finne på fakta\n",
    "- Verifiser alltid medisinsk informasjon\n",
    "- Bruk lav temperature for faktabaserte spørsmål\n",
    "\n",
    "**3. Logging**\n",
    "- Logg alle API-kall for sporbarhet\n",
    "- Slett logger med pasientinformasjon i henhold til policy\n",
    "\n",
    "**4. Menneskelig tilsyn**\n",
    "- AI-output skal alltid vurderes av helsepersonell\n",
    "- Implementer tydelige advarsler i brukergrensesnitt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Oppsummering\n",
    "\n",
    "### Hovedpunkter\n",
    "\n",
    "1. **API-nøkler** skal aldri hardkodes - bruk miljøvariabler\n",
    "2. **Feilhåndtering** med retry-logikk er essensielt\n",
    "3. **System prompts** med sikkerhetsinstruksjoner er kritisk for medisinsk bruk\n",
    "4. **Personvern** må ivaretas - vurder lokale modeller for sensitiv data\n",
    "5. **Menneskelig tilsyn** er alltid påkrevd for medisinsk AI\n",
    "\n",
    "### Ressurser\n",
    "\n",
    "- [OpenAI API dokumentasjon](https://platform.openai.com/docs)\n",
    "- [Anthropic API dokumentasjon](https://docs.anthropic.com)\n",
    "- [OpenAI Cookbook](https://cookbook.openai.com/)\n",
    "\n",
    "---\n",
    "\n",
    "*Tilbake til [Lab 3 oversikt](../README.md)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "elmed219-2026",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
